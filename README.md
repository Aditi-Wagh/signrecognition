Specially abled people use hand signs and gestures to communicate. Normal people face
difficulty in understanding their language. Hence there is a need for a software application
which recognizes the different signs, gestures and conveys the information to normal
people. The machine learning model that recognises sign language and displays the output
in text form is developed.Thus it bridges the gap between physically challenged people and
normal people.
The model uses machine learning and computer vision to recognize hand gestures and predict
 using the K-Nearest Neighbors (KNN) algorithm.
